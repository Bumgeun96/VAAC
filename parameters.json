{
    "SparseHopper-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"SparseHopper-v1",
        "n_steps": 1000,
        "n_total_steps": 1000000,
        "n_eval": 1,
        "n_seeds": 5,
        "sparsity_level":5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "noveld",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 30,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.05,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.05,
        "beta_scheduling":0,
        "beta_init":1,
        "beta_decay_freq":1000,
        "beta_decay_rate":0.01,
        "min_beta": 0.2,

        "__comment8__":"re3 parameters",
        "re3_scale":0.05,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.05,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.05
    },
    "SparseWalker2d-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"SparseWalker2d-v1",
        "n_steps": 1000,
        "n_total_steps": 2000000,
        "n_eval": 1,
        "n_seeds": 5,
        "sparsity_level":5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "re3",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.01,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.1,
        "im_beta": 0.01,
        "beta_scheduling":0,
        "beta_init":0.5,
        "beta_decay_freq":3000,
        "beta_decay_rate":0.01,
        "min_beta": 0.01,

        "__comment8__":"re3 parameters",
        "re3_scale":0.01,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.01,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.01

    },
    "SparseAnt-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"SparseAnt-v1",
        "n_steps": 1000,
        "n_total_steps": 3000000,
        "n_eval": 1,
        "n_seeds": 5,
        "sparsity_level":5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "sac",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.15,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":1000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.07,
        "beta_scheduling":0,
        "beta_init":0.8,
        "beta_decay_freq":2000,
        "beta_decay_rate":0.01,
        "min_beta": 0.05,

        "__comment8__":"re3 parameters",
        "re3_scale":0.15,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.15,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.15
    },
    "SparseHalfCheetah-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"SparseHalfCheetah-v1",
        "n_steps": 1000,
        "n_total_steps": 1000000,
        "n_eval": 1,
        "n_seeds": 5,
        "sparsity_level":5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.05,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.05,
        "beta_scheduling":0,
        "beta_init":0.5,
        "beta_decay_freq":1000,
        "beta_decay_rate":0.01,
        "min_beta": 0.1,

        "__comment8__":"re3 parameters",
        "re3_scale":0.05,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.05,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.05
    },
    "DelayedHopper-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"DelayedHopper-v1",
        "n_steps": 1000,
        "n_total_steps": 1000000,
        "n_eval": 1,
        "n_seeds": 5,
        "delayed_level":30,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac(ac)",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 30,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.05,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.05,
        "beta_scheduling":0,
        "beta_init":1,
        "beta_decay_freq":1000,
        "beta_decay_rate":0.01,
        "min_beta": 0.2,

        "__comment8__":"re3 parameters",
        "re3_scale":0.05,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.05,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.05
    },
    "DelayedWalker2d-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"DelayedWalker2d-v1",
        "n_steps": 1000,
        "n_total_steps": 2000000,
        "n_eval": 1,
        "n_seeds": 5,
        "delayed_level":20,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.01,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.1,
        "im_beta": 0.01,
        "beta_scheduling":0,
        "beta_init":0.5,
        "beta_decay_freq":3000,
        "beta_decay_rate":0.01,
        "min_beta": 0.01,

        "__comment8__":"re3 parameters",
        "re3_scale":0.01,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.01,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.01

    },
    "DelayedAnt-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"DelayedAnt-v1",
        "n_steps": 1000,
        "n_total_steps": 3000000,
        "n_eval": 1,
        "n_seeds": 5,
        "delayed_level":20,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac(ac)",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.15,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":1000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.02,
        "beta_scheduling":0,
        "beta_init":0.8,
        "beta_decay_freq":2000,
        "beta_decay_rate":0.01,
        "min_beta": 0.05,

        "__comment8__":"re3 parameters",
        "re3_scale":0.15,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.15,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.15
    },
    "DelayedHalfCheetah-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"DelayedHalfCheetah-v1",
        "n_steps": 1000,
        "n_total_steps": 1000000,
        "n_eval": 1,
        "n_seeds": 5,
        "delayed_level":20,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac(ac)",

        "__comment3__":"Dynamics model parameters",
        "latent_size": 50,

        "__comment4__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        "rnd_reward_scaling": 0.05,
        
        "__comment5__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment6__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment7__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.05,
        "beta_scheduling":0,
        "beta_init":0.5,
        "beta_decay_freq":1000,
        "beta_decay_rate":0.01,
        "min_beta": 0.1,

        "__comment8__":"re3 parameters",
        "re3_scale":0.05,

        "__comment9__":"icm parameters",
        "icm_beta":0.2,
        "icm_reward_scaling":0.05,

        "__comment10__":"noveld parameters",
        "noveld_alpha":0.5,
        "noveld_reward_scaling":0.05
    },
    "HumanoidStandup-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"HumanoidStandup-v1",
        "n_steps": 1000,
        "n_total_steps": 3000000,
        "n_eval": 1,
        "n_seeds": 5,
        "sparsity_level":5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "vaac",

        "__comment3__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        
        "__comment4__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment5__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment6__":"VAAC parameters",
        "rnd_frequency":10000,
        "rnd_reset":0,
        "im_alpha": 0.2,
        "im_beta": 0.01,
        "beta_scheduling":0,
        "beta_init":0.1,
        "beta_decay_freq":3000,
        "beta_decay_rate":0.001,
        "min_beta": 0.001
    },
    "Humanoid-v1":
    {
        "__comment1__":"Env_parameters",
        "env":"Humanoid-v1",
        "n_steps": 1000,
        "n_total_steps": 1000000,
        "n_eval": 1,
        "n_seeds": 5,

        "__comment2__":"RL parameters",
        "gamma": 0.99,
        "learning_start": 10000,
        "algorithm": "sac",

        "__comment3__":"RND parameters",
        "action_std_decay_freq": 50000,
        "action_std_init": 0.6,
        "action_std_decay_rate": 0.05,
        "min_action_std": 0.1,
        "max_grad_norm":0.5,
        "clip_coef":0.2,
        "ent_coef":0.01,
        "vf_coef":0.5,
        "k_epochs": 40,
        "update_timestep": 4000,
        
        "__comment4__":"Off-policy parameters",
        "reward_scale": 5,
        "buffer_size": 1000000,
        "tau": 0.005,
        "batch_size": 256,
        "actor_lr": 0.0003,
        "critic_lr": 0.001,
        "policy_frequency": 2,
        "target_network_frequency": 1,

        "__comment5__":"SAC parameters",
        "alpha": 0.2,
        "auto_tune": 1,

        "__comment6__":"VAAC parameters",
        "rnd_frequency":10000,
        "im_alpha": 0.2,
        "im_beta": 0.1,
        "beta_scheduling":1,
        "beta_init":0.1,
        "beta_decay_freq":10000,
        "beta_decay_rate":0.001,
        "min_beta": 0.001
    }
}